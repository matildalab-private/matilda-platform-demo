name: Train model
inputs:
- {name: train_dataset, type: Dataset}
- {name: loaded_model, type: TFModel}
outputs:
- {name: trained_weights, type: Weights}
implementation:
  container:
    image: tensorflow/tensorflow:2.2.0
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'numpy' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'numpy' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n   \
      \ os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
      \ndef train_model(\n    train_dataset,\n    loaded_model,\n    trained_weights\n\
      ):\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras.callbacks\
      \ import (\n        ReduceLROnPlateau,\n        EarlyStopping,\n        ModelCheckpoint\n\
      \    )\n    from tensorflow.keras.losses import (\n        binary_crossentropy,\n\
      \        sparse_categorical_crossentropy\n    )\n\n    def _meshgrid(n_a, n_b):\n\
      \        return [\n            tf.reshape(tf.tile(tf.range(n_a), [n_b]), (n_b,\
      \ n_a)),\n            tf.reshape(tf.repeat(tf.range(n_b), n_a), (n_b, n_a))\n\
      \        ]\n\n    def broadcast_iou(box_1, box_2):\n        # box_1: (..., (x1,\
      \ y1, x2, y2))\n        # box_2: (N, (x1, y1, x2, y2))\n\n        # broadcast\
      \ boxes\n        box_1 = tf.expand_dims(box_1, -2)\n        box_2 = tf.expand_dims(box_2,\
      \ 0)\n        # new_shape: (..., N, (x1, y1, x2, y2))\n        new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1),\
      \ tf.shape(box_2))\n        box_1 = tf.broadcast_to(box_1, new_shape)\n    \
      \    box_2 = tf.broadcast_to(box_2, new_shape)\n\n        int_w = tf.maximum(tf.minimum(box_1[...,\
      \ 2], box_2[..., 2]) -\n                        tf.maximum(box_1[..., 0], box_2[...,\
      \ 0]), 0)\n        int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3])\
      \ -\n                        tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\n\
      \        int_area = int_w * int_h\n        box_1_area = (box_1[..., 2] - box_1[...,\
      \ 0]) * \\\n            (box_1[..., 3] - box_1[..., 1])\n        box_2_area\
      \ = (box_2[..., 2] - box_2[..., 0]) * \\\n            (box_2[..., 3] - box_2[...,\
      \ 1])\n        return int_area / (box_1_area + box_2_area - int_area)\n\n  \
      \  def yolo_boxes(pred, anchors, classes):\n        # pred: (batch_size, grid,\
      \ grid, anchors, (x, y, w, h, obj, ...classes))\n        grid_size = tf.shape(pred)[1:3]\n\
      \        box_xy, box_wh, objectness, class_probs = tf.split(\n            pred,\
      \ (2, 2, 1, classes), axis=-1)\n\n        box_xy = tf.sigmoid(box_xy)\n    \
      \    objectness = tf.sigmoid(objectness)\n        class_probs = tf.sigmoid(class_probs)\n\
      \        pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for\
      \ loss\n\n        # !!! grid[x][y] == (y, x)\n        grid = _meshgrid(grid_size[1],grid_size[0])\n\
      \        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy,\
      \ 1, 2]\n\n        box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\n    \
      \        tf.cast(grid_size, tf.float32)\n        box_wh = tf.exp(box_wh) * anchors\n\
      \n        box_x1y1 = box_xy - box_wh / 2\n        box_x2y2 = box_xy + box_wh\
      \ / 2\n        bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n\n        return\
      \ bbox, objectness, class_probs, pred_box\n\n    def YoloLoss(anchors, classes=6,\
      \ ignore_thresh=0.5):\n        def yolo_loss(y_true, y_pred):\n            #\
      \ 1. transform all pred outputs\n            # y_pred: (batch_size, grid, grid,\
      \ anchors, (x, y, w, h, obj, ...cls))\n            pred_box, pred_obj, pred_class,\
      \ pred_xywh = yolo_boxes(\n                y_pred, anchors, classes)\n     \
      \       pred_xy = pred_xywh[..., 0:2]\n            pred_wh = pred_xywh[...,\
      \ 2:4]\n\n            # 2. transform all true outputs\n            # y_true:\
      \ (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n          \
      \  true_box, true_obj, true_class_idx = tf.split(\n                y_true, (4,\
      \ 1, 1), axis=-1)\n            true_xy = (true_box[..., 0:2] + true_box[...,\
      \ 2:4]) / 2\n            true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n\
      \n            # give higher weights to small boxes\n            box_loss_scale\
      \ = 2 - true_wh[..., 0] * true_wh[..., 1]\n\n            # 3. inverting the\
      \ pred box equations\n            grid_size = tf.shape(y_true)[1]\n        \
      \    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n        \
      \    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n            true_xy\
      \ = true_xy * tf.cast(grid_size, tf.float32) - \\\n                tf.cast(grid,\
      \ tf.float32)\n            true_wh = tf.math.log(true_wh / anchors)\n      \
      \      true_wh = tf.where(tf.math.is_inf(true_wh),\n                       \
      \     tf.zeros_like(true_wh), true_wh)\n\n            # 4. calculate all masks\n\
      \            obj_mask = tf.squeeze(true_obj, -1)\n            # ignore false\
      \ positive when iou is over threshold\n            best_iou = tf.map_fn(\n \
      \               lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\n\
      \                    x[1], tf.cast(x[2], tf.bool))), axis=-1),\n           \
      \     (pred_box, true_box, obj_mask),\n                tf.float32)\n       \
      \     ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n\n      \
      \      # 5. calculate all losses\n            xy_loss = obj_mask * box_loss_scale\
      \ * \\\n                tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n\
      \            wh_loss = obj_mask * box_loss_scale * \\\n                tf.reduce_sum(tf.square(true_wh\
      \ - pred_wh), axis=-1)\n            obj_loss = binary_crossentropy(true_obj,\
      \ pred_obj)\n            obj_loss = obj_mask * obj_loss + \\\n             \
      \   (1 - obj_mask) * ignore_mask * obj_loss\n            # TODO: use binary_crossentropy\
      \ instead\n            class_loss = obj_mask * sparse_categorical_crossentropy(\n\
      \                true_class_idx, pred_class)\n\n            # 6. sum over (batch,\
      \ gridx, gridy, anchors) => (batch, 1)\n            xy_loss = tf.reduce_sum(xy_loss,\
      \ axis=(1, 2, 3))\n            wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2,\
      \ 3))\n            obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n    \
      \        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n\n        \
      \    return xy_loss + wh_loss + obj_loss + class_loss\n        return yolo_loss\n\
      \n    IMAGE_FEATURE_MAP = {\n        'image/encoded': tf.io.FixedLenFeature([],\
      \ tf.string),\n        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n\
      \        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n      \
      \  'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n        'image/object/bbox/ymax':\
      \ tf.io.VarLenFeature(tf.float32),\n        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n\
      \    }\n\n    def parse_tfrecord(tfrecord, class_table, size):\n        x =\
      \ tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n        x_train =\
      \ tf.image.decode_jpeg(x['image/encoded'], channels=3)\n        x_train = tf.image.resize(x_train,\
      \ (size, size))\n\n        class_text = tf.sparse.to_dense(\n            x['image/object/class/text'],\
      \ default_value='')\n        labels = tf.cast(class_table.lookup(class_text),\
      \ tf.float32)\n        y_train = tf.stack([tf.sparse.to_dense(x['image/object/bbox/xmin']),\n\
      \                            tf.sparse.to_dense(x['image/object/bbox/ymin']),\n\
      \                            tf.sparse.to_dense(x['image/object/bbox/xmax']),\n\
      \                            tf.sparse.to_dense(x['image/object/bbox/ymax']),\n\
      \                            labels], axis=1)\n\n        paddings = [[0, 100\
      \ - tf.shape(y_train)[0]], [0, 0]]\n        y_train = tf.pad(y_train, paddings)\n\
      \n        return x_train, y_train\n\n    def load_tfrecord_dataset(file_pattern,\
      \ size=416):\n        keys_tensor = tf.constant(['missing_hole', 'mouse_bite',\
      \ 'open_circuit', 'short', 'spur', 'spurious_copper'])\n        vals_tensor\
      \ = tf.constant([0, 1, 2, 3, 4, 5])\n        init = tf.lookup.KeyValueTensorInitializer(keys_tensor,\
      \ vals_tensor)\n        class_table = tf.lookup.StaticHashTable(init, default_value=-1)\n\
      \        # LINE_NUMBER = -1  # TODO: use tf.lookup.TextFileIndex.LINE_NUMBER\n\
      \        # class_table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n\
      \        #     class_file, tf.string, 0, tf.int64, LINE_NUMBER, delimiter=\"\
      \\n\"), -1)\n        files = tf.data.Dataset.list_files(file_pattern)\n    \
      \    dataset = files.flat_map(tf.data.TFRecordDataset)\n        return dataset.map(lambda\
      \ x: parse_tfrecord(x, class_table, size))\n\n    @tf.function\n    def transform_targets_for_output(y_true,\
      \ grid_size, anchor_idxs):\n        # y_true: (N, boxes, (x1, y1, x2, y2, class,\
      \ best_anchor))\n        N = tf.shape(y_true)[0]\n\n        # y_true_out: (N,\
      \ grid, grid, anchors, [x1, y1, x2, y2, obj, class])\n        y_true_out = tf.zeros(\n\
      \            (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n\n   \
      \     anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n\n        indexes = tf.TensorArray(tf.int32,\
      \ 1, dynamic_size=True)\n        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n\
      \        idx = 0\n        for i in tf.range(N):\n            for j in tf.range(tf.shape(y_true)[1]):\n\
      \                if tf.equal(y_true[i][j][2], 0):\n                    continue\n\
      \                anchor_eq = tf.equal(\n                    anchor_idxs, tf.cast(y_true[i][j][5],\
      \ tf.int32))\n\n                if tf.reduce_any(anchor_eq):\n             \
      \       box = y_true[i][j][0:4]\n                    box_xy = (y_true[i][j][0:2]\
      \ + y_true[i][j][2:4]) / 2\n\n                    anchor_idx = tf.cast(tf.where(anchor_eq),\
      \ tf.int32)\n                    grid_xy = tf.cast(box_xy // (1/grid_size),\
      \ tf.int32)\n\n                    # grid[y][x][anchor] = (tx, ty, bw, bh, obj,\
      \ class)\n                    indexes = indexes.write(\n                   \
      \     idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n                \
      \    updates = updates.write(\n                        idx, [box[0], box[1],\
      \ box[2], box[3], 1, y_true[i][j][4]])\n                    idx += 1\n\n   \
      \     # tf.print(indexes.stack())\n        # tf.print(updates.stack())\n\n \
      \       return tf.tensor_scatter_nd_update(\n            y_true_out, indexes.stack(),\
      \ updates.stack())\n\n    def transform_targets(y_train, anchors, anchor_masks,\
      \ size):\n        y_outs = []\n        grid_size = size // 32\n\n        # calculate\
      \ anchor index for true boxes\n        anchors = tf.cast(anchors, tf.float32)\n\
      \        anchor_area = anchors[..., 0] * anchors[..., 1]\n        box_wh = y_train[...,\
      \ 2:4] - y_train[..., 0:2]\n        box_wh = tf.tile(tf.expand_dims(box_wh,\
      \ -2),\n                        (1, 1, tf.shape(anchors)[0], 1))\n        box_area\
      \ = box_wh[..., 0] * box_wh[..., 1]\n        intersection = tf.minimum(box_wh[...,\
      \ 0], anchors[..., 0]) * \\\n            tf.minimum(box_wh[..., 1], anchors[...,\
      \ 1])\n        iou = intersection / (box_area + anchor_area - intersection)\n\
      \        anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n       \
      \ anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n\n        y_train = tf.concat([y_train,\
      \ anchor_idx], axis=-1)\n\n        for anchor_idxs in anchor_masks:\n      \
      \      y_outs.append(transform_targets_for_output(\n                y_train,\
      \ grid_size, anchor_idxs))\n            grid_size *= 2\n\n        return tuple(y_outs)\n\
      \n    def transform_images(x_train, size):\n        x_train = tf.image.resize(x_train,\
      \ (size, size))\n        x_train = x_train / 255\n        return x_train\n\n\
      \    anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),(59,\
      \ 119), (116, 90), (156, 198), (373, 326)],np.float32) / 416\n    anchor_masks\
      \ = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n\n    train_dataset = load_tfrecord_dataset(train_dataset)\n\
      \    train_dataset = train_dataset.shuffle(buffer_size=512)\n    train_dataset\
      \ = train_dataset.batch(8)\n    train_dataset = train_dataset.map(lambda x,\
      \ y: (\n        transform_images(x, 416),\n        transform_targets(y, anchors,\
      \ anchor_masks, 416)))\n    train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n\
      \n    model = tf.keras.models.load_model(loaded_model, custom_objects={'yolo_loss':[[YoloLoss(anchors[mask],\
      \ classes=6) for mask in anchor_masks]]})\n\n    callbacks = [\n        ReduceLROnPlateau(verbose=1),\n\
      \        EarlyStopping(patience=5, verbose=1),\n    ]\n\n    import os\n   \
      \ os.mkdir(trained_weights)\n\n    model.fit(train_dataset, epochs=1, callbacks=callbacks)\
      \    \n    model.save_weights(trained_weights+'/trained_weights.tf')\n    print(os.listdir('tmp/outputs/trained_weights/data/'))\n\
      \nimport argparse\n_parser = argparse.ArgumentParser(prog='Train model', description='')\n\
      _parser.add_argument(\"--train-dataset\", dest=\"train_dataset\", type=str,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--loaded-model\"\
      , dest=\"loaded_model\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--trained-weights\", dest=\"trained_weights\", type=_make_parent_dirs_and_return_path,\
      \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
      \n_outputs = train_model(**_parsed_args)\n"
    args:
    - --train-dataset
    - {inputPath: train_dataset}
    - --loaded-model
    - {inputPath: loaded_model}
    - --trained-weights
    - {outputPath: trained_weights}
